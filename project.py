# -*- coding: utf-8 -*-
"""project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1W7px-2C5uoBfOz0wg0--IrhQzpf9pc3m
"""

from google.colab import drive
drive.mount('/content/gdrive')

!unzip 'drive/My Drive/plant-disease.zip'

# Run this cell to mount your Google Drive.
from google.colab import drive
drive.mount('/content/drive')

import glob
import numpy as np
import matplotlib.pyplot as plt
from keras.preprocessing.image import ImageDataGenerator,img_to_array,array_to_img,load_img

train_datagen=ImageDataGenerator(rescale=1./255,zoom_range=0.3,
                                 rotation_range=50,width_shift_range=0.2,height_shift_range=0.2,
                                 horizontal_flip=True,fill_mode='nearest')
validation_datagen=ImageDataGenerator(rescale=1./255)

training_set=train_datagen.flow_from_directory("dataset/train",
                                                target_size=(224,224),batch_size=128,
                                                class_mode='categorical')

validation_set=validation_datagen.flow_from_directory("dataset/test",
                                                      target_size=(224,224),batch_size=128,
                                                      class_mode='categorical')

class_dict = training_set.class_indices
print(class_dict)

li = list(class_dict.keys())
print(li)

"""# VGG MODEL"""

from keras.applications import vgg16
from keras.models import Model
import keras

vgg = vgg16.VGG16(include_top=False, weights='imagenet', 
                                     input_shape=(224,224,3))

output = vgg.layers[-1].output
output = keras.layers.Flatten()(output)

vgg_model = Model(vgg.input, output)
vgg_model.trainable = False

for layer in vgg_model.layers:
    layer.trainable = False

vgg_model.summary()

from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, InputLayer
from keras.models import Sequential
from keras import optimizers

model = Sequential()
model.add(vgg_model)
model.add(Dense(512, activation='relu', input_dim=(224,224,3)))
model.add(Dropout(0.3))
model.add(Dense(512, activation='relu'))
model.add(Dropout(0.3))
model.add(Dense(38, activation='softmax'))

model.compile(loss='categorical_crossentropy',
              optimizer=optimizers.RMSprop(lr=2e-5),
              metrics=['accuracy'])

model.summary()

train_num = training_set.samples
valid_num = validation_set.samples
batch_size=32
# checkpoint
from keras.callbacks import ModelCheckpoint
weightpath = "Raj.hdf5"
checkpoint = ModelCheckpoint(weightpath, monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=True, mode='max')
callbacks_list = [checkpoint]

#fitting images to CNN
history = model.fit_generator(training_set,
                         steps_per_epoch=1000,
                         validation_data=validation_set,
                         epochs=5  ,
                         validation_steps=100,
                         callbacks=callbacks_list)

model.save('plant-disease.h5')

import matplotlib.pyplot as plt
import seaborn as sns
sns.set()

acc = history.history['acc']
val_acc = history.history['val_acc']
loss = history.history['loss']
val_loss = history.history['val_loss']
epochs = range(1, len(loss) + 1)


plt.plot(epochs, acc, color='green', label='Training Accuracy')
plt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.ylabel('Accuracy')
plt.xlabel('Epoch')
plt.legend()
plt.figure()

plt.plot(epochs, loss, color='gray', label='Training Loss')
plt.plot(epochs, val_loss, color='red', label='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.legend()

plt.show()

from keras.preprocessing import image
import numpy as np
image_path = "plant1/dataset/test/Grape___Black_rot/02f75392-dbad-4ab8-a35d-d391f9d57113___FAM_B.Rot 3323.JPG"
new_img = image.load_img(image_path, target_size=(224, 224))
img = image.img_to_array(new_img)
img = np.expand_dims(img, axis=0)
img = img/255

prediction = model.predict(img)
d=np.argmax(prediction)
class_name=li[d]        
plt.figure(figsize = (4,4))
plt.imshow(new_img)
plt.axis('off')
plt.show()
print(class_name)